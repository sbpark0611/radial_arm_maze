Using cpu device
tot num of params: 93813
Logging to /Users/sangbin/radial_arm_maze/outputs/2024-04-12/11-30-32/wandb/run-20240412_113033-rh1dccg1/files/rh1dccg1/PPO_1
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 128      |
|    ep_rew_mean        | 1.24     |
|    fraction_of_oracle | 0.0484   |
|    oracle_reward      | 25.6     |
| time/                 |          |
|    fps                | 1215     |
|    iterations         | 1        |
|    time_elapsed       | 13       |
|    total_timesteps    | 16384    |
------------------------------------
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.max_episode_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_episode_steps` for environment variables or `env.get_wrapper_attr('max_episode_steps')` that will search the reminding wrappers.
  logger.warn(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.oracle_min_num_actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.oracle_min_num_actions` for environment variables or `env.get_wrapper_attr('oracle_min_num_actions')` that will search the reminding wrappers.
  logger.warn(
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 128       |
|    ep_rew_mean          | 1.37      |
|    fraction_of_oracle   | 0.0535    |
|    oracle_reward        | 25.6      |
| time/                   |           |
|    fps                  | 178       |
|    iterations           | 2         |
|    time_elapsed         | 183       |
|    total_timesteps      | 32768     |
| train/                  |           |
|    approx_kl            | 0.0317145 |
|    clip_fraction        | 0.0295    |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.37     |
|    explained_variance   | -0.00789  |
|    grad_norm            | 0.341     |
|    learning_rate        | 2e-05     |
|    loss                 | 0.249     |
|    n_updates            | 5         |
|    policy_gradient_loss | -0.00533  |
|    value_loss           | 0.51      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.48       |
|    fraction_of_oracle   | 0.0578     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 139        |
|    iterations           | 3          |
|    time_elapsed         | 353        |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.08287801 |
|    clip_fraction        | 0.0315     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | 0.0271     |
|    grad_norm            | 0.408      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.06       |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.00503   |
|    value_loss           | 0.166      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.31       |
|    fraction_of_oracle   | 0.0512     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 125        |
|    iterations           | 4          |
|    time_elapsed         | 520        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.16315493 |
|    clip_fraction        | 0.0135     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.0586     |
|    grad_norm            | 0.354      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0937     |
|    n_updates            | 15         |
|    policy_gradient_loss | -0.00351   |
|    value_loss           | 0.167      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.12       |
|    fraction_of_oracle   | 0.0438     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 5          |
|    time_elapsed         | 690        |
|    total_timesteps      | 81920      |
| train/                  |            |
|    approx_kl            | 0.19456792 |
|    clip_fraction        | 0          |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.122      |
|    grad_norm            | 0.623      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.065      |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.00187   |
|    value_loss           | 0.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.23       |
|    fraction_of_oracle   | 0.048      |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 6          |
|    time_elapsed         | 870        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.24629778 |
|    clip_fraction        | 0.0118     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | 0.165      |
|    grad_norm            | 0.4        |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0319     |
|    n_updates            | 25         |
|    policy_gradient_loss | -0.00296   |
|    value_loss           | 0.115      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.12       |
|    fraction_of_oracle   | 0.0438     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 7          |
|    time_elapsed         | 1048       |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.24500492 |
|    clip_fraction        | 0.00439    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.116      |
|    grad_norm            | 0.415      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0397     |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.00161   |
|    value_loss           | 0.116      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.3        |
|    fraction_of_oracle   | 0.0508     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 8          |
|    time_elapsed         | 1233       |
|    total_timesteps      | 131072     |
| train/                  |            |
|    approx_kl            | 0.20865405 |
|    clip_fraction        | 0.0053     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.167      |
|    grad_norm            | 0.419      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0437     |
|    n_updates            | 35         |
|    policy_gradient_loss | -0.00243   |
|    value_loss           | 0.0999     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.14       |
|    fraction_of_oracle   | 0.0445     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 9          |
|    time_elapsed         | 1412       |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.21395674 |
|    clip_fraction        | 0.00297    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.128      |
|    grad_norm            | 0.546      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.106      |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.00233   |
|    value_loss           | 0.129      |
----------------------------------------
Traceback (most recent call last):
  File "/Users/sangbin/radial_arm_maze/train_epn_ram.py", line 88, in <module>
    main()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/Users/sangbin/radial_arm_maze/train_epn_ram.py", line 75, in main
    model.learn(total_timesteps=cfg.optim.total_timesteps, callback=callback)
  File "/Users/sangbin/radial_arm_maze/ppo/epn/epn.py", line 511, in learn
    self.train()
  File "/Users/sangbin/radial_arm_maze/ppo/epn/epn.py", line 411, in train
    loss.backward()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt