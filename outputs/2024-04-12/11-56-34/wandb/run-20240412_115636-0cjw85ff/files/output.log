Using cpu device
tot num of params: 93813
Logging to /Users/sangbin/radial_arm_maze/outputs/2024-04-12/11-56-34/wandb/run-20240412_115636-0cjw85ff/files/0cjw85ff/PPO_1
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 128      |
|    ep_rew_mean        | 1.29     |
|    fraction_of_oracle | 0.0504   |
|    oracle_reward      | 25.6     |
| time/                 |          |
|    fps                | 1098     |
|    iterations         | 1        |
|    time_elapsed       | 14       |
|    total_timesteps    | 16384    |
------------------------------------
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.max_episode_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_episode_steps` for environment variables or `env.get_wrapper_attr('max_episode_steps')` that will search the reminding wrappers.
  logger.warn(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.oracle_min_num_actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.oracle_min_num_actions` for environment variables or `env.get_wrapper_attr('oracle_min_num_actions')` that will search the reminding wrappers.
  logger.warn(
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 128         |
|    ep_rew_mean          | 1.34        |
|    fraction_of_oracle   | 0.0523      |
|    oracle_reward        | 25.6        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 2           |
|    time_elapsed         | 189         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.029497907 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.00133     |
|    grad_norm            | 0.347       |
|    learning_rate        | 2e-05       |
|    loss                 | 0.285       |
|    n_updates            | 5           |
|    policy_gradient_loss | -0.00395    |
|    value_loss           | 0.532       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 128         |
|    ep_rew_mean          | 1.43        |
|    fraction_of_oracle   | 0.0559      |
|    oracle_reward        | 25.6        |
| time/                   |             |
|    fps                  | 133         |
|    iterations           | 3           |
|    time_elapsed         | 368         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.077947274 |
|    clip_fraction        | 0.0224      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | 0.0542      |
|    grad_norm            | 0.35        |
|    learning_rate        | 2e-05       |
|    loss                 | 0.058       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00465    |
|    value_loss           | 0.148       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.24       |
|    fraction_of_oracle   | 0.0484     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 120        |
|    iterations           | 4          |
|    time_elapsed         | 545        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.14419207 |
|    clip_fraction        | 0.00878    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.0505     |
|    grad_norm            | 0.36       |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0712     |
|    n_updates            | 15         |
|    policy_gradient_loss | -0.00258   |
|    value_loss           | 0.145      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 128      |
|    ep_rew_mean          | 1.11     |
|    fraction_of_oracle   | 0.0434   |
|    oracle_reward        | 25.6     |
| time/                   |          |
|    fps                  | 113      |
|    iterations           | 5        |
|    time_elapsed         | 721      |
|    total_timesteps      | 81920    |
| train/                  |          |
|    approx_kl            | 0.150641 |
|    clip_fraction        | 0.00101  |
|    clip_range           | 0.2      |
|    entropy_loss         | -1.31    |
|    explained_variance   | 0.0879   |
|    grad_norm            | 0.499    |
|    learning_rate        | 2e-05    |
|    loss                 | 0.0694   |
|    n_updates            | 20       |
|    policy_gradient_loss | -0.00191 |
|    value_loss           | 0.129    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.22       |
|    fraction_of_oracle   | 0.0477     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 6          |
|    time_elapsed         | 899        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.15009418 |
|    clip_fraction        | 3.66e-05   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.0765     |
|    grad_norm            | 0.505      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0404     |
|    n_updates            | 25         |
|    policy_gradient_loss | -0.00134   |
|    value_loss           | 0.127      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.1        |
|    fraction_of_oracle   | 0.043      |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 7          |
|    time_elapsed         | 1077       |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.19002312 |
|    clip_fraction        | 0.00138    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.1        |
|    grad_norm            | 0.491      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0608     |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.00208   |
|    value_loss           | 0.127      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.31       |
|    fraction_of_oracle   | 0.0512     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 8          |
|    time_elapsed         | 1254       |
|    total_timesteps      | 131072     |
| train/                  |            |
|    approx_kl            | 0.23541537 |
|    clip_fraction        | 0.0122     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.112      |
|    grad_norm            | 0.409      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0287     |
|    n_updates            | 35         |
|    policy_gradient_loss | -0.00314   |
|    value_loss           | 0.113      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.42       |
|    fraction_of_oracle   | 0.0555     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 9          |
|    time_elapsed         | 1431       |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.20962048 |
|    clip_fraction        | 0.00396    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.123      |
|    grad_norm            | 0.39       |
|    learning_rate        | 2e-05      |
|    loss                 | 0.061      |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.00235   |
|    value_loss           | 0.123      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 128       |
|    ep_rew_mean          | 1.22      |
|    fraction_of_oracle   | 0.0477    |
|    oracle_reward        | 25.6      |
| time/                   |           |
|    fps                  | 92        |
|    iterations           | 10        |
|    time_elapsed         | 1764      |
|    total_timesteps      | 163840    |
| train/                  |           |
|    approx_kl            | 0.1838528 |
|    clip_fraction        | 0.00573   |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.3      |
|    explained_variance   | 0.131     |
|    grad_norm            | 0.335     |
|    learning_rate        | 2e-05     |
|    loss                 | 0.0766    |
|    n_updates            | 45        |
|    policy_gradient_loss | -0.00223  |
|    value_loss           | 0.124     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.21       |
|    fraction_of_oracle   | 0.0473     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 11         |
|    time_elapsed         | 2152       |
|    total_timesteps      | 180224     |
| train/                  |            |
|    approx_kl            | 0.19396539 |
|    clip_fraction        | 0.0019     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.16       |
|    grad_norm            | 0.472      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0451     |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00199   |
|    value_loss           | 0.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.18       |
|    fraction_of_oracle   | 0.0461     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 77         |
|    iterations           | 12         |
|    time_elapsed         | 2521       |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.21363291 |
|    clip_fraction        | 0.0102     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.147      |
|    grad_norm            | 0.41       |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0428     |
|    n_updates            | 55         |
|    policy_gradient_loss | -0.00257   |
|    value_loss           | 0.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.68       |
|    fraction_of_oracle   | 0.0656     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 13         |
|    time_elapsed         | 2890       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.21533716 |
|    clip_fraction        | 0.00105    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.17       |
|    grad_norm            | 0.477      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0241     |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.00204   |
|    value_loss           | 0.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.58       |
|    fraction_of_oracle   | 0.0617     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 14         |
|    time_elapsed         | 3238       |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.20624541 |
|    clip_fraction        | 0.00188    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.154      |
|    grad_norm            | 0.51       |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0781     |
|    n_updates            | 65         |
|    policy_gradient_loss | -0.00215   |
|    value_loss           | 0.138      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.56       |
|    fraction_of_oracle   | 0.0609     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 15         |
|    time_elapsed         | 3495       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.23262672 |
|    clip_fraction        | 0.00476    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.153      |
|    grad_norm            | 0.521      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0666     |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.00282   |
|    value_loss           | 0.138      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.7        |
|    fraction_of_oracle   | 0.0664     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 16         |
|    time_elapsed         | 3745       |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.25682423 |
|    clip_fraction        | 0.00524    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | 0.201      |
|    grad_norm            | 0.505      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0779     |
|    n_updates            | 75         |
|    policy_gradient_loss | -0.00263   |
|    value_loss           | 0.131      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.64       |
|    fraction_of_oracle   | 0.0641     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 59         |
|    iterations           | 17         |
|    time_elapsed         | 4701       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.23819977 |
|    clip_fraction        | 0.033      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.152      |
|    grad_norm            | 0.661      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0506     |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.00387   |
|    value_loss           | 0.138      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 128        |
|    ep_rew_mean          | 1.66       |
|    fraction_of_oracle   | 0.0648     |
|    oracle_reward        | 25.6       |
| time/                   |            |
|    fps                  | 52         |
|    iterations           | 18         |
|    time_elapsed         | 5644       |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.20867342 |
|    clip_fraction        | 0.0147     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.19       |
|    grad_norm            | 0.683      |
|    learning_rate        | 2e-05      |
|    loss                 | 0.0708     |
|    n_updates            | 85         |
|    policy_gradient_loss | -0.00318   |
|    value_loss           | 0.133      |
----------------------------------------
Traceback (most recent call last):
  File "/Users/sangbin/radial_arm_maze/train_epn_ram.py", line 88, in <module>
    main()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/Users/sangbin/radial_arm_maze/train_epn_ram.py", line 75, in main
    model.learn(total_timesteps=cfg.optim.total_timesteps, callback=callback)
  File "/Users/sangbin/radial_arm_maze/ppo/epn/epn.py", line 511, in learn
  File "/Users/sangbin/radial_arm_maze/ppo/epn/epn.py", line 411, in train
    loss.backward()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt